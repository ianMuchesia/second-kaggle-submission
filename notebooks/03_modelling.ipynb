{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b065354",
   "metadata": {},
   "source": [
    "# BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3a1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332ef102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import normalize_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd57428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26debd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]\n",
    "X = df.drop(columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c14198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = normalize_data(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d83ee7",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1874f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128571428571428\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='saga',max_iter=1000)\n",
    "\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60850c8d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c1d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9644047619047619\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test,rf_y_pred)\n",
    "\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca0b32",
   "metadata": {},
   "source": [
    "## 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780b8bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf scores : [0.95997024 0.9641369  0.95982143 0.959375   0.96577381]\n",
      "lf scores : [0.91949405 0.91949405 0.90803571 0.91339286 0.91651786]\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_val_score(rf_model,X_train,y_train,cv=5)\n",
    "lr_scores = cross_val_score(log_reg,X_train,y_train,cv=5)\n",
    "\n",
    "\n",
    "print(\"rf scores :\", rf_scores)\n",
    "print(\"lf scores :\", lr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed08f6",
   "metadata": {},
   "source": [
    "## Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c518e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean random forst: 0.9618154761904762 Mean logistic regrerssion: 0.9153869047619047\n",
      "Standard Deviation random forest: 0.002622765218674795 Standard Deviation Logistic Regression: 0.004313525831850424\n"
     ]
    }
   ],
   "source": [
    "mean_rf = np.mean(rf_scores)\n",
    "std_rf = np.std(rf_scores)\n",
    "\n",
    "\n",
    "mean_lr = np.mean(lr_scores)\n",
    "std_lr = np.std(lr_scores)\n",
    "\n",
    "\n",
    "print(f\"Mean random forst: {mean_rf} Mean logistic regrerssion: {mean_lr}\")\n",
    "print(f\"Standard Deviation random forest: {std_rf} Standard Deviation Logistic Regression: {std_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf0cae",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528cab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([33600, 784])\n",
      "y shape: torch.Size([33600])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values,dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values,dtype=torch.long)\n",
    "\n",
    "#checks shapes\n",
    "print(f\"X shape: {X_train_tensor.shape}\")\n",
    "print(f\"y shape: {y_train_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb7ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(MNISTNet,self).__init__()\n",
    "        #layer 1 -> takes 9 inputs and outputs t a hidden layer(e.g 16 neurons)\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64,128)\n",
    "        \n",
    "        self.fc4 = nn.Linear(128,10)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        #x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet(input_size=784)    \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#define the optimizer (Learning rate is a knob we can tune later!)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001) \n",
    "\n",
    "\n",
    "# Weight decay\n",
    "schedular = optim.lr_scheduler.StepLR(optimizer,step_size=40,gamma=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6492caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6136e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2513\n",
      "Epoch [20/100], Loss: 0.2865\n",
      "Epoch [30/100], Loss: 0.0555\n",
      "Epoch [40/100], Loss: 0.0511\n",
      "Epoch [50/100], Loss: 0.1128\n",
      "Epoch [60/100], Loss: 0.0101\n",
      "Epoch [70/100], Loss: 0.0056\n",
      "Epoch [80/100], Loss: 0.0158\n",
      "Epoch [90/100], Loss: 0.0014\n",
      "Epoch [100/100], Loss: 0.0772\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images ,labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "    schedular.step()\n",
    "\n",
    "    if (epoch + 1)  % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9615d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guesses: 33430\n",
      "accuracy: 99.49%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    \n",
    "    raw_outputs = model(X_train_tensor)\n",
    "    \n",
    "    predictions = torch.argmax(raw_outputs,dim=1)\n",
    "    \n",
    "    \n",
    "# print(predictions.shape)\n",
    "# print(y_train_tensor.shape)\n",
    "    \n",
    "correct_maske = predictions == y_train_tensor\n",
    "\n",
    "num_correct = correct_maske.sum().item()\n",
    "print(f\"Number of correct guesses: {num_correct}\")\n",
    "\n",
    "\n",
    "#optionally , compute accuracy\n",
    "accuracy = num_correct /len(y_train_tensor)\n",
    "print(f\"accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f760218",
   "metadata": {},
   "source": [
    "## 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "722e70aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 0.0417, LR: 0.000080\n",
      "Fold 1  Accuracy: 0.9737\n",
      "Epoch [50/100], Loss: 0.0472, LR: 0.000080\n",
      "Fold 2  Accuracy: 0.9686\n",
      "Epoch [50/100], Loss: 0.0209, LR: 0.000080\n",
      "Fold 3  Accuracy: 0.9705\n",
      "Epoch [50/100], Loss: 0.3071, LR: 0.000080\n",
      "Fold 4  Accuracy: 0.9707\n",
      "Epoch [50/100], Loss: 0.0050, LR: 0.000080\n",
      "Fold 5  Accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tensor)):\n",
    "    \n",
    "    model = MNISTNet(input_size=784)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    #define the optimizer (Learning rate is a knob we can tune later!)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.0001) \n",
    "    \n",
    "    \n",
    "    #2. Slice the tensors for this fold\n",
    "    X_train_fold = X_train_tensor[train_idx]\n",
    "    y_train_fold = y_train_tensor[train_idx]\n",
    "    X_val_fold = X_train_tensor[val_idx]\n",
    "    y_val_fold = y_train_tensor[val_idx]\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_fold,y_train_fold)\n",
    "    \n",
    "    train_loader  = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.8)\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        for images,labels in train_loader:\n",
    "    \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}, LR: {current_lr:.6f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    #validation phase (no tracking here)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_fold)\n",
    "        val_preds = torch.argmax(val_outputs,dim=1)\n",
    "        \n",
    "        \n",
    "        correct = (val_preds == y_val_fold).sum().item()\n",
    "        \n",
    "        fold_acc = correct/len(y_val_fold)\n",
    "        \n",
    "        \n",
    "        fold_results.append(fold_acc)\n",
    "        print(f\"Fold {fold+1}  Accuracy: {fold_acc:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a708767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./../data/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32847a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized_test = normalize_data(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9fbd7",
   "metadata": {},
   "source": [
    "### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16c25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_test_predict = rf_model.predict(X_normalized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b23825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\":range(1,len(rf_y_test_predict) + 1),\n",
    "    \"Label\": rf_y_test_predict\n",
    "})\n",
    "submission.to_csv(\"./../data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772cade",
   "metadata": {},
   "source": [
    "### Neural Networks test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc4b1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([8400, 784])\n",
      "y shape: torch.Size([8400])\n",
      "X test shape: torch.Size([28000, 784])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values,dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values,dtype=torch.long)\n",
    "X_test_tensor_normalized = torch.tensor(X_normalized_test.values,dtype=torch.float32)\n",
    "\n",
    "#checks shapes\n",
    "print(f\"X shape: {X_test_tensor.shape}\")\n",
    "print(f\"y shape: {y_test_tensor.shape}\")\n",
    "print(f\"X test shape: {X_test_tensor_normalized.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa219f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct guesses: 8150\n",
      "accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    \n",
    "    raw_outputs = model(X_test_tensor)\n",
    "    \n",
    "    predictions = torch.argmax(raw_outputs,dim=1)\n",
    "    \n",
    "    \n",
    "# print(predictions.shape)\n",
    "# print(y_train_tensor.shape)\n",
    "    \n",
    "correct_maske = predictions == y_test_tensor\n",
    "\n",
    "num_correct = correct_maske.sum().item()\n",
    "print(f\"Number of correct guesses: {num_correct}\")\n",
    "\n",
    "\n",
    "#optionally , compute accuracy\n",
    "accuracy = num_correct /len(y_test_tensor)\n",
    "print(f\"accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f80f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    \n",
    "    raw_outputs = model(X_test_tensor_normalized)\n",
    "    \n",
    "    predictions = torch.argmax(raw_outputs,dim=1)\n",
    "    \n",
    "    \n",
    "# print(predictions.shape)\n",
    "# print(y_train_tensor.shape)\n",
    "    \n",
    "pred_list = predictions.numpy()\n",
    "\n",
    "# Create the DataFrame\n",
    "# Kaggle's ImageId is 1-indexed\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, len(pred_list) + 1),\n",
    "    \"Label\": pred_list\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"./../data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db2cf6",
   "metadata": {},
   "source": [
    "## Feature Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05603ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance tells us how much a pixel \"spreads out\" from its average value.\n",
    "pixel_variances = torch.var(X_train_tensor,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f1d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality Reduction\n",
    "mask = pixel_variances > 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de2354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 0.0278, LR: 0.000080\n",
      "Fold 1  Accuracy: 0.9750\n",
      "Epoch [50/100], Loss: 0.0172, LR: 0.000080\n",
      "Fold 2  Accuracy: 0.9695\n",
      "Epoch [50/100], Loss: 0.0112, LR: 0.000080\n",
      "Fold 3  Accuracy: 0.9766\n",
      "Epoch [50/100], Loss: 0.0025, LR: 0.000080\n",
      "Fold 4  Accuracy: 0.9743\n",
      "Epoch [50/100], Loss: 0.1095, LR: 0.000080\n",
      "Fold 5  Accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "    \n",
    "X_train_reduced = X_train_tensor[:,mask]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_reduced)):\n",
    "    \n",
    "    model = MNISTNet(input_size=546)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    #define the optimizer (Learning rate is a knob we can tune later!)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.0001) \n",
    "    \n",
    "    \n",
    "    #2. Slice the tensors for this fold\n",
    "    X_train_fold = X_train_reduced[train_idx]\n",
    "    y_train_fold = y_train_tensor[train_idx]\n",
    "    X_val_fold = X_train_reduced[val_idx]\n",
    "    y_val_fold = y_train_tensor[val_idx]\n",
    "    \n",
    "    #X_val_reduced = X_val_fold[:,mask]\n",
    "\n",
    "\n",
    "    \n",
    "    #print(X_train_reduced.shape)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_fold,y_train_fold)\n",
    "    \n",
    "    train_loader  = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.8)\n",
    "    \n",
    "    \n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "\n",
    "        for images,labels in train_loader:\n",
    "    \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}, LR: {current_lr:.6f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    #validation phase (no tracking here)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_fold)\n",
    "        val_preds = torch.argmax(val_outputs,dim=1)\n",
    "        \n",
    "        \n",
    "        correct = (val_preds == y_val_fold).sum().item()\n",
    "        \n",
    "        fold_acc = correct/len(y_val_fold)\n",
    "        \n",
    "        \n",
    "        fold_results.append(fold_acc)\n",
    "        print(f\"Fold {fold+1}  Accuracy: {fold_acc:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
